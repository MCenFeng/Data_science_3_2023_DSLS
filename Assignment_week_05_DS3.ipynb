{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio assignment week 5\n",
    "1. SVC\n",
    "The Scikit-learn library provides different kernels for the Support Vector Classifier, e.g. RBF or polynomial.\n",
    "\n",
    "Based on the examples in the accompanying notebook, create your own SVC class and configure it with different kernels to see if you are able to have it correctly separate the moon-dataset. You can also use a precomputed kernel. In addition, there are several parameters you can tune to for better results. Make sure to go through the documentation.\n",
    "\n",
    "Hint:\n",
    "\n",
    "Plot the support vectors for understanding how it works.\n",
    "Give arguments why a certain kernel behaves a certain way.\n",
    "2. Model Evaluation\n",
    "Classification metrics are important for measuring the performance of your model. Scikit-learn provides several options such as the classification_report and confusion_matrix functions. Another helpful option is the AUC ROC and precision-recall curve. Try to understand what these metrics mean and give arguments why one metric would be more important then others.\n",
    "\n",
    "For instance, if you have to predict whether a patient has cancer or not, the number of false negatives is probably more important than the number of false positives. This would be different if we were predicting whether a picture contains a cat or a dog â€“ or not: it all depends on the context. Thus, it is important to understand when to use which metric.\n",
    "\n",
    "For this exercise, you can use your own dataset if that is eligable for supervised classification. Otherwise, you can use the breast cancer dataset which you can find on assemblix2019 (/data/datasets/DS3/). Go through the data science pipeline as you've done before:\n",
    "\n",
    "Try to understand the dataset globally.\n",
    "Load the data.\n",
    "Exploratory analysis\n",
    "Preprocess data (skewness, normality, etc.)\n",
    "Modeling (cross-validation and training)\n",
    "Evaluation\n",
    "Create and train several LogisticRegression and SVM models with different values for their hyperparameters. Make use of the model evaluation techniques that have been described during the plenary part to determine the best model for this dataset. Accompany you elaborations with a conclusion, in which you explicitely interpret these evaluation and describe why the different metrics you are using are important or not. Make sure you take the context of this dataset into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data file\n",
    "data_brc = pd.read_csv('datasets_DS3\\\\breast-cancer.csv')\n",
    "\n",
    "data_brc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_brc.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_brc.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_brc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_brc.dtypes == 'object'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_brc.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_brc.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_brc['diagnosis'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning and modifying the data\n",
    "data_brc_clean = data_brc.drop('id',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping Benign to 0 and Malignant to 1 \n",
    "data_brc_clean['diagnosis'] = data_brc_clean['diagnosis'].map({'M':1,'B':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_brc_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_mat = data_brc_clean.corr()\n",
    "# Strip out the diagonal values for the next step\n",
    "for x in range(len(data_brc_clean.columns)):\n",
    "    corr_mat.iloc[x,x] = 0.0\n",
    "    \n",
    "corr_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see which features are highly correlated\n",
    "# Pairwise maximal correlations\n",
    "corr_mat.abs().idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how much are they correlated? Can we eliminate certain features based on high correlations\n",
    "corr_mat.abs().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .skew 0: no skew, + right skew, - left skew, look for above .75 \n",
    "skew_columns = (data_brc_clean\n",
    "                .skew()\n",
    "                .sort_values(ascending=False))\n",
    "\n",
    "skew_columns = skew_columns.loc[skew_columns > 0.75]\n",
    "skew_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform log transform on skewed columns\n",
    "for col in skew_columns.index.tolist():\n",
    "    data_brc_clean[col] = np.log1p(data_brc_clean[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_context('notebook')\n",
    "sns.pairplot(data_brc_clean, \n",
    "             hue='diagnosis');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the code above is taken from: https://github.com/fenna/BFVM23DATASCNC5/blob/main/Exercises/E_Clustering_breast_cancer_solution.ipynb\n",
    "### the above code is also used for the subsequent assignments of week 6 and 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(data_brc_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_features = scaler.transform(data_brc_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_brc_clean.drop('diagnosis', axis=1)\n",
    "y= data_brc_clean['diagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_brc_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_train shape:\",X_train.shape)\n",
    "print(\"X_test shape:\",X_test.shape)\n",
    "print(\"y_train shape:\",y_train.shape)\n",
    "print(\"y_test shape:\",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To store results of models\n",
    "result_dict_train = {}\n",
    "result_dict_test = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_model_1 = LogisticRegression(max_iter=5000)\n",
    "accuracies = cross_val_score(lr_model_1, X_train, y_train, cv=5)\n",
    "lr_model_1.fit(X_train, y_train)\n",
    "\n",
    "print(\"Train Score:\",np.mean(accuracies))\n",
    "print(\"Test Score:\",lr_model_1.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict_train[\"Logistic regression Default Train Score\"] = np.mean(accuracies)\n",
    "result_dict_test[\"Logistic regression Default Test Score\"] = lr_model_1.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_space = np.logspace(-5, 8, 15)\n",
    "param_grid = {'C': c_space}\n",
    "  \n",
    "# Instantiating logistic regression classifier\n",
    "logreg = LogisticRegression(max_iter=4000)\n",
    "  \n",
    "# Instantiating the GridSearchCV object\n",
    "logreg_cv = GridSearchCV(logreg, param_grid, cv = 5)\n",
    "logreg_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\",logreg_cv.best_params_)\n",
    "print(\"Train Score:\",logreg_cv.best_score_)\n",
    "print(\"Test Score:\",logreg_cv.score(X_test,y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine (supervised learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc_model_2 = SVC(random_state = 101)\n",
    "accuracies = cross_val_score(svc_model_2, X_train, y_train, cv=5)\n",
    "svc_model_2.fit(X_train,y_train)\n",
    "\n",
    "print(\"Train Score:\",np.mean(accuracies))\n",
    "print(\"Test Score:\",svc_model_2.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict_train[\"SVM Default Train Score\"] = np.mean(accuracies)\n",
    "result_dict_test[\"SVM Default Test Score\"] = svc_model_2.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {\n",
    "    'C':[0.01,0.1,1,10],\n",
    "    'kernel' : [\"linear\",\"poly\",\"rbf\",\"sigmoid\"],\n",
    "    'degree' : [1,3,5,7],\n",
    "    'gamma' : [0.01,1]\n",
    "}\n",
    "\n",
    "svm  = SVC ()\n",
    "svm_cv = GridSearchCV(svm, grid, cv = 5)\n",
    "svm_cv.fit(X_train,y_train)\n",
    "print(\"Best Parameters:\",svm_cv.best_params_)\n",
    "print(\"Train Score:\",svm_cv.best_score_)\n",
    "print(\"Test Score:\",svm_cv.score(X_test,y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUC ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression\n",
    "model1 = LogisticRegression()\n",
    "# knn\n",
    "model2 = SVC(kernel='poly')\n",
    "\n",
    "# fit model\n",
    "model1.fit(X_train, y_train)\n",
    "model2.fit(X_train, y_train)\n",
    "\n",
    "# predict probabilities\n",
    "pred_prob1 = model1.predict(X_test)\n",
    "pred_prob2 = model2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc curve for models\n",
    "fpr1, tpr1, thresh1 = roc_curve(y_test, pred_prob1, pos_label=1)\n",
    "fpr2, tpr2, thresh2 = roc_curve(y_test, pred_prob2, pos_label=1)\n",
    "\n",
    "# roc curve for tpr = fpr \n",
    "random_probs = [0 for i in range(len(y_test))]\n",
    "p_fpr, p_tpr, _ = roc_curve(y_test, random_probs, pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auc scores\n",
    "auc_score1 = roc_auc_score(y_test, pred_prob1)\n",
    "auc_score2 = roc_auc_score(y_test, pred_prob2)\n",
    "\n",
    "print('Logistic regression AUC Score: ' ,auc_score1,'SVC AUC Score: ' ,auc_score2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the code used above is taken from: https://github.com/AnshulSaini17/Income_evaluation/blob/main/Income_Evalutation.ipynb\n",
    "### and https://www.analyticsvidhya.com/blog/2020/06/auc-roc-curve-machine-learning/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AUC score from the Logistic regression is excellent when applied on this dataset. it has a good classification performance on the data, also for support vector machine (SVC), the model scored very high on the dataset for classifiaction based on Malignant and benign tumors. However, logistic regression performed a bit better compred to the SVC model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
