{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio Assignment week 01\n",
    "\n",
    "## Write a brief summary about the following:\n",
    "\n",
    "\n",
    "##### What are common preprocessing steps? Explain for each step why and when you should execute this step and when not.\n",
    "\n",
    "The common preprocessing steps are: \n",
    "- checking for and removal of missing values (such as NaNs) \n",
    "- imputation of the missing data\n",
    "- checking for outliers in the dataset\n",
    "- Transforming the data (1.Dimensionality reduction, 2.Standardization, 3. Normalization, 4.Binning, and 5.Clustering)\n",
    "- Dealing with imbalanced data (1.Undersampling = a.Near Miss Undersampling, b.Condensed Nearest Neighbor Rule Undersampling and c.Tomek Links for Undersampling\n",
    "  2.Oversampling = a.SMOTE and b.Random Sampling)\n",
    "\n",
    "\n",
    "##### What visualization methods are used in the cluster methods tutorial? Explain why the selected method is the most appropriate method for the visualization. Bonus points: do this as well for the scanpy tutorial.\n",
    "\n",
    "Clustering methods notebook:\n",
    "- Histogram is used to visualize the distribution of the data\n",
    "- Pairplots to compare the various features of the data, this give a better insight to distinguish datapoints of the features used\n",
    "- A line/scatterplot is used to plot the datapoints of the feature to by comparing the x-axis to the y-axis\n",
    "- A dendrogram is used to visualize and represent the relationship between the features in the data as a way to measure their similarity to each other\n",
    "\n",
    "\n",
    "Cluster scanpy method object notebook:\n",
    "- Violin plot is used to observe the distribution of numeric data and is useful to make a comparison of distributions between multiple groups\n",
    "- - A line/scatterplot is used to plot the datapoints of the feature to by comparing the x-axis to the y-axis, thus the relationship between the variables in the data\n",
    "- UMAP plot is used to visualize the clustering results of the data by reducing the data to 2-dimension, which arranges the data in a low-dimensional space \n",
    "\n",
    "\n",
    "##### What performance/evaluation metrics are in the cluster methods tutorial? Explain why the used methods are the most appropriate method for the evaluation.\n",
    "\n",
    "\n",
    "- K-Means clustering model \n",
    "- Agglomerative clustering model\n",
    "- Logistic Regression model\n",
    "\n",
    "K-Means method: appropriate Evaluation Method, one of the most commonly used methods for evaluating K-Means clustering is the Silhouette Score. The Silhouette Score measures how similar each data point in one cluster is to the data points in the neighboring clusters. It quantifies the separation between clusters and can help identify the optimal number of clusters (k) by looking for the highest Silhouette Score.K-Means clustering is an unsupervised learning technique used for data segmentation and grouping. Since it doesn't have a clear \"ground truth\" like classification tasks, evaluation metrics like Silhouette Score provide a quantitative measure of cluster quality. Other metrics like Davies-Bouldin Index or within-cluster sum of squares (WCSS) can also be used depending on your specific goals.\n",
    "\n",
    "Agglomerative clustering method: similar to K-Means, the Silhouette Score and Davies-Bouldin Index can be used for Agglomerative clustering.Agglomerative clustering, like K-Means, is also an unsupervised clustering technique. Therefore, the same rationale applies here as for K-Means.The Silhouette Score helps in assessing the quality and separation of clusters, while the Davies-Bouldin Index measures the average similarity between each cluster and its most similar cluster. These metrics can guide the selection of the number of clusters and assess the quality of the clustering result.\n",
    "\n",
    "Logistic Regression method: commonly used evaluation methods for a Logistic Regression model include accuracy, precision, recall, F1-score, ROC curve, and AUC-ROC. Logistic Regression is a supervised learning technique used for binary or multiclass classification. In classification tasks, we often have a clear \"ground truth\" label for each data point, making accuracy, precision, recall, F1-score, ROC curve, and AUC-ROC suitable evaluation metrics.Accuracy measures the overall correct predictions, while precision and recall provide insights into the model's ability to correctly classify positive instances. F1-score combines precision and recall into a single metric. ROC curve and AUC-ROC assess the model's performance at different classification thresholds, particularly when dealing with imbalanced datasets. The choice of evaluation metric depends on the problem's specific goals. For example, if false positives and false negatives have different costs, precision-recall or F1-score might be more relevant than accuracy.\n",
    "\n",
    "\n",
    "##### Bonus:\n",
    "##### You practice the steps yourself with the breast_cancer dataset (clustering_data.csv) \n",
    "##### Study the Tutorial tutorial_cluster_scanpy_object and the tutorial_Clustering_Methods   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the answers are taken from: https://towardsdatascience.com/what-are-the-most-important-preprocessing-steps-in-machine-learning-and-data-science-a7606d18f32a"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
